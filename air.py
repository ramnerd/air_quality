# ============================== #
#   ğŸ“¦ Import Libraries          #
# ============================== #
import pandas as pd
import numpy as np
import seaborn as sns
import matplotlib.pyplot as plt

# For ignoring warnings (cleaner output)
import warnings
warnings.filterwarnings("ignore")

print("\nâœ… Libraries imported successfully!")


# ======================================== #
#   ğŸ“‚ Step 1: Load the Dataset            #
# ======================================== #
file_path = "air\\data.csv"
df = pd.read_csv(file_path, encoding='latin1')  # or 'ISO-8859-1'

print("\nğŸ“Š Dataset loaded!")
print("ğŸ” Shape of dataset:", df.shape)
print("ğŸ§¾ Columns:\n", df.columns.tolist())


# ======================================== #
#   ğŸ§¹ Step 2: Basic Cleanup               #
# ======================================== #
print("\nğŸ”§ Checking for null values...")
print(df.isnull().sum())

# Optional: Rename confusing columns
df = df.rename(columns={
    'state': 'State',
    'location': 'City',
    'type': 'Area_Category',
    'so2': 'Sulphur_Dioxide',
    'no2': 'Nitrogen_Dioxide',
    'rspm': 'RSPM',
    'spm': 'SPM'
})

print("\nâœ… Columns renamed for clarity!")


# ======================================== #
#   ğŸ§ª Step 3: Data Types + Basic Info     #
# ======================================== #
print("\nğŸ§¬ Dataset Info:")
print(df.info())

print("\nğŸ“ˆ Summary Statistics:")
print(df.describe(include='all'))


# ======================================== #
#   ğŸ§¼ Step 4: Missing Data Treatment      #
# ======================================== #
print("\nğŸ” Checking % of missing values per column:")
missing_percent = df.isnull().mean() * 100
print(missing_percent)

# If too much missing, decide what to do (you can use dropna, fillna etc.)
# For example, let's just fill NA pollution values with the column mean for now
for col in ['Sulphur_Dioxide', 'Nitrogen_Dioxide', 'RSPM', 'SPM']:
    if df[col].isnull().sum() > 0:
        df[col] = df[col].fillna(df[col].mean())
        print(f"âœ… Filled missing values in '{col}' with mean.")


# ======================================== #
#   ğŸ“Š Step 5: Value Counts for Categories #
# ======================================== #
print("\nğŸ§¾ Unique value counts:")
for col in ['State', 'City', 'Area_Category']:
    print(f"\n{col}:\n", df[col].value_counts(normalize=True) * 100)


# # ======================================== #
# #   ğŸ“ˆ Step 6: Pollution Trends Analysis   #
# # ======================================== #

# ğŸ‘‰ Average pollutants per Area_Category
print("\nğŸ“Œ Average pollution levels by Area Category:")
area_pollution = df.groupby('Area_Category')[
    ['Sulphur_Dioxide', 'Nitrogen_Dioxide', 'RSPM', 'SPM']].mean()
print(area_pollution)

# ğŸ‘‰ Plot Area category vs pollution
area_pollution.plot(kind='bar', figsize=(10, 6))
plt.title("ğŸ“Š Pollution Levels by Area Category")
plt.ylabel("Concentration (Âµg/mÂ³)")
plt.xlabel("Area Category")
plt.grid(True)
plt.tight_layout()
plt.show()


# ======================================== #
#   ğŸ“ˆ Step 7: State-wise Comparison       #
# ======================================== #
state_pollution = df.groupby('State')[
    ['Sulphur_Dioxide', 'Nitrogen_Dioxide']].mean().sort_values(by='Nitrogen_Dioxide', ascending=False)

print("\nğŸï¸ Top states with highest Nitrogen Dioxide levels:")
print(state_pollution.head())

state_pollution.plot(kind='bar', figsize=(14, 6))
plt.title("ğŸŒ† State-wise Average Pollution (SO2 & NO2)")
plt.ylabel("Concentration (Âµg/mÂ³)")
plt.xticks(rotation=90)
plt.tight_layout()
plt.grid(True)
plt.show()



# # ======================================== #
# #   ğŸ“Š Step 9: Correlation Matrix          #
# # ======================================== #
print("\nğŸ§  Correlation between pollutants:")
corr = df[['Sulphur_Dioxide', 'Nitrogen_Dioxide', 'RSPM', 'SPM']].corr()
print(corr)

sns.heatmap(corr, annot=True, cmap='coolwarm')
plt.title("ğŸ”— Correlation between Pollutants")
plt.tight_layout()
plt.show()
